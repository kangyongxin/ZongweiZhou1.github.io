<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YixiaoZhou&#39;s blog</title>
  
  <subtitle>修行路上的科研小站</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-05-23T02:09:02.865Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>zongweizhou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>阅读笔记-Deep Affinity Network for Multiple Object Tracking</title>
    <link href="http://yoursite.com/2019/05/22/SST-DAN/"/>
    <id>http://yoursite.com/2019/05/22/SST-DAN/</id>
    <published>2019-05-22T14:54:00.000Z</published>
    <updated>2019-05-23T02:09:02.865Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2019/05/22/SST-DAN/DAN.png&quot; alt=&quot;DAN&quot;&gt;&lt;/p&gt;
&lt;p&gt;MOT方法一般包含两个步骤:目标检测和数据关联。 目标检测这两年随着深度学习的发展而迅速发展，但是数据关联绝大多数还是采用hand crafted的方式将表观特征，运动信息，空间关系，group关系等进行结合。 这篇文章则是利用深度网络实现端到端的表观特征抽取和数据关联。 Deep Affinity Network(DAN)还实现了轨迹的初始化和终止等操作。在MOT15和MOT17，以及UA-DETRAC数据集上验证了有效性。这篇文章和上篇笔记FANTrack的出发点类似。&lt;/p&gt;
&lt;p&gt;项目地址： &lt;a href=&quot;https://github.com/shijieS/SST.git&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/shijieS/SST.git&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="MOT" scheme="http://yoursite.com/tags/MOT/"/>
    
      <category term="Affinity Network" scheme="http://yoursite.com/tags/Affinity-Network/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记-FANTrack：3DMulti-Object Tracking with Feature Association Network</title>
    <link href="http://yoursite.com/2019/05/22/FANTrack/"/>
    <id>http://yoursite.com/2019/05/22/FANTrack/</id>
    <published>2019-05-22T14:44:12.000Z</published>
    <updated>2019-05-22T14:51:07.490Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2019/05/22/FANTrack/siamese similarity.png&quot; alt=&quot;siamese similarity&quot;&gt;&lt;/p&gt;
&lt;p&gt;目前大多数深度学习的方法主要基于特征的学习， 代价函数的设计，或者如何有效解决复杂的数据关联模型，很少有利用CNN网络端到端解决MOT的。本文提出使用CNN解决data association问题。该方案纯粹利用数据，从3D的角度实现全局的数据关联，同时处理noisy detections以及目标个数变化等问题。&lt;/p&gt;
&lt;p&gt;文章提供代码： &lt;a href=&quot;https://git.uwaterloo.ca/wise-lab/fantrack&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://git.uwaterloo.ca/wise-lab/fantrack&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="MOT" scheme="http://yoursite.com/tags/MOT/"/>
    
      <category term="KITTI" scheme="http://yoursite.com/tags/KITTI/"/>
    
      <category term="Feature Association Network" scheme="http://yoursite.com/tags/Feature-Association-Network/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记-Relation Network for Object Detection</title>
    <link href="http://yoursite.com/2019/05/22/relationNetwork/"/>
    <id>http://yoursite.com/2019/05/22/relationNetwork/</id>
    <published>2019-05-22T13:35:35.000Z</published>
    <updated>2019-05-22T14:39:12.377Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2019/05/22/relationNetwork/title.png&quot; alt=&quot;title&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们都知道在目标检测领域，深度学习(RCNN系列，YOLO系列，SSD系列)方法取得了很大的成功，但是这些检测方法考虑的仅仅是目标的个体，而没有考虑一帧图像中目标之间的相互影响，所以本文提出一种&lt;strong&gt;object relation module&lt;/strong&gt; ,通过考虑目标集合中个体的交互关系来辅助目标的检测。该模块参数很少能够很方便的嵌入到已有的网络中，提高目标检测性能，另外本文使用该模块实现duplicate removal（NMS实现的功能），从而能够实现网络的end-to-end学习。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考_&lt;/strong&gt; : 在多目标跟踪问题中，一般的计算两个目标之间是否匹配的策略还是类似于ReID的方法，仅考虑两者之间的相似度，但是在跟踪的时空图中，两个观测的关系不仅仅取决于两者之间的关系，还取决于同时存在的其他目标之间的关系，所以多目标的匹配策略同样可以使用类似的relation module。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Relation Network" scheme="http://yoursite.com/tags/Relation-Network/"/>
    
      <category term="Object Detection" scheme="http://yoursite.com/tags/Object-Detection/"/>
    
      <category term="GCN" scheme="http://yoursite.com/tags/GCN/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记-Repulsion loss:Detecting Pedestrians in a Crowd</title>
    <link href="http://yoursite.com/2019/05/21/repulsion-loss/"/>
    <id>http://yoursite.com/2019/05/21/repulsion-loss/</id>
    <published>2019-05-21T10:58:08.000Z</published>
    <updated>2019-05-22T01:04:34.755Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;p&gt;尽管目标检测目前已经取得了非常好的性能，但是针对于特定领域内的跟踪方法还可以进一步探讨。本篇文章的研究重点在于更好的检测拥挤场景下的行人。&lt;/p&gt;
&lt;p&gt;文章首先分析了拥挤场景下SOTA检测方法存在的问题，然后提出了一种针对于拥挤场景专门设计的回归损失。该损失函数的启发源主要有两点：预测框应该尽可能和目标接近；同时预测框应尽可能地与surrounding目标区分。&lt;/p&gt;
&lt;p&gt;实验证明本文提出的损失函数能够在拥挤场景中很大提升SOTA方法的性能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Pedestrian Detection" scheme="http://yoursite.com/tags/Pedestrian-Detection/"/>
    
      <category term="Repulsion Loss" scheme="http://yoursite.com/tags/Repulsion-Loss/"/>
    
  </entry>
  
  <entry>
    <title>多目标跟踪总结(下)-资源汇总</title>
    <link href="http://yoursite.com/2019/05/21/MOT-overview-3rd/"/>
    <id>http://yoursite.com/2019/05/21/MOT-overview-3rd/</id>
    <published>2019-05-21T03:37:35.000Z</published>
    <updated>2019-05-22T00:49:12.058Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;导言&quot;&gt;&lt;a href=&quot;#导言&quot; class=&quot;headerlink&quot; title=&quot;导言&quot;&gt;&lt;/a&gt;导言&lt;/h3&gt;&lt;p&gt;本文主要收集MOT领域的一些资源， 包括数据集，相关论文以及部分开源代码等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MOT" scheme="http://yoursite.com/tags/MOT/"/>
    
      <category term="overview" scheme="http://yoursite.com/tags/overview/"/>
    
      <category term="code and paper" scheme="http://yoursite.com/tags/code-and-paper/"/>
    
  </entry>
  
  <entry>
    <title>多目标跟踪总结(中)-深度方法</title>
    <link href="http://yoursite.com/2019/05/20/MOT-overview-2nd/"/>
    <id>http://yoursite.com/2019/05/20/MOT-overview-2nd/</id>
    <published>2019-05-20T08:30:36.000Z</published>
    <updated>2019-05-22T00:47:42.391Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;导言&quot;&gt;&lt;a href=&quot;#导言&quot; class=&quot;headerlink&quot; title=&quot;导言&quot;&gt;&lt;/a&gt;导言&lt;/h3&gt;&lt;p&gt;随着深度学习的推进，基于深度学习的检测器性能提升明显。因此目前的多目标跟踪算法大都基于tracking-by-detection框架。于是MOT任务可以转化为detection+ReID问题。&lt;/p&gt;
&lt;p&gt;但相对于与传统的ReID问题，MOT问题会更加复杂。首先，MOT任务中目标轨迹变化频繁， 图像样本库的数量和种类都不固定； 其次，检测结果可能出现新的目标，也可能出现漏检；另外，检测图像并不像行人重识别中的查询图像都是比较准确地检测结果， MOT任务中行人检测往往混杂着误检或者不准确的检测，尤其是相互遮挡产生时。检测行人的不对齐，相互遮挡给目标匹配带来了极大的挑战性。&lt;/p&gt;
&lt;p&gt;本文将主要总结一些基于深度网络，希望更好解决MOT任务中ReID子任务的方法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MOT" scheme="http://yoursite.com/tags/MOT/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>多目标跟踪总结(上)-传统方法</title>
    <link href="http://yoursite.com/2019/05/20/MOT-overview-1st/"/>
    <id>http://yoursite.com/2019/05/20/MOT-overview-1st/</id>
    <published>2019-05-20T00:55:26.000Z</published>
    <updated>2019-05-22T00:48:56.463Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;导言&quot;&gt;&lt;a href=&quot;#导言&quot; class=&quot;headerlink&quot; title=&quot;导言&quot;&gt;&lt;/a&gt;导言&lt;/h3&gt;&lt;p&gt;参考SIGAI公众号推文，欢迎关注SIGAI公众号。&lt;/p&gt;
&lt;p&gt;目标跟踪是计算机视觉中的一个重要任务。在计算机视觉的三层结构中，目标跟踪属于中间层，是其他高层任务，如动作识别、行为分析等，的基础。 其广泛应用于视频监控，人机交互，自动驾驶， 医学图像，虚拟现实和增强现实等现实场景中。目标跟踪根据每帧跟踪目标个数不同又划分为单目标跟踪(Single Object Tracking, SOT)和多目标跟踪(Multiple Object Tracking, MOT)。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MOT" scheme="http://yoursite.com/tags/MOT/"/>
    
      <category term="overview" scheme="http://yoursite.com/tags/overview/"/>
    
      <category term="traditional method" scheme="http://yoursite.com/tags/traditional-method/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记-Evaluation Multiple Object Tracking Performance-The CLEAR MOT Metrics</title>
    <link href="http://yoursite.com/2019/05/19/CLEAR/"/>
    <id>http://yoursite.com/2019/05/19/CLEAR/</id>
    <published>2019-05-19T10:23:48.000Z</published>
    <updated>2019-05-21T15:09:11.181Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;p&gt;原发表于&lt;a href=&quot;https://www.cnblogs.com/YiXiaoZhou/p/5937980.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CLEAR&lt;/a&gt;， 参考之前笔记&lt;a href=&quot;https://zongweizhou1.github.io/2019/05/17/MOT16-A-Benchmark-for-Multi-Object-Tracking/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MOT16&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;多目标跟踪问题的评价指标应该能够评估三个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目标是否都及时的找到。&lt;/li&gt;
&lt;li&gt;目标跟踪到的位置和真实位置一致性程度。&lt;/li&gt;
&lt;li&gt;是否能够保持跟踪的一致性。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="MOT" scheme="http://yoursite.com/tags/MOT/"/>
    
      <category term="CLEAR" scheme="http://yoursite.com/tags/CLEAR/"/>
    
      <category term="Metric" scheme="http://yoursite.com/tags/Metric/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记-Spatial-Temporal Relation Networks for Multi-Object Tracking</title>
    <link href="http://yoursite.com/2019/05/19/STRN/"/>
    <id>http://yoursite.com/2019/05/19/STRN/</id>
    <published>2019-05-19T10:20:40.000Z</published>
    <updated>2019-05-22T13:22:58.035Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;p&gt;鲁棒的相似度度量是MOT取得较好性能的一个关键。而鲁棒的相似度度量应该能够变现表观、位置、时间和空间信息。由于这些线索差异性较大，不能直接组合在一起，一般的MOT方法会分别使用网络处理这些特征。&lt;/p&gt;
&lt;p&gt;本文提出了一种Spatial-Temporal Relation network能够同时encode多种线索，并从时空关系中推理轨迹和检测的匹配关系。该网络能够端到端的训练并在MOT15-17benchmark上都取得了SOTA的性能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/05/19/STRN/STRN.png&quot; alt=&quot;STRN&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="MOT" scheme="http://yoursite.com/tags/MOT/"/>
    
      <category term="Spatial-Temporal Relational Network" scheme="http://yoursite.com/tags/Spatial-Temporal-Relational-Network/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记-High-speed tracking with kernelized correlation filters</title>
    <link href="http://yoursite.com/2019/05/18/High-speed-tracking-with-kernelized-correlation-filters/"/>
    <id>http://yoursite.com/2019/05/18/High-speed-tracking-with-kernelized-correlation-filters/</id>
    <published>2019-05-18T12:41:36.000Z</published>
    <updated>2019-05-21T15:08:41.260Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;p&gt;​        KCF是一种鉴别式追踪方法，这类方法一般都是在追踪过程中训练一个目标检测器，使用目标检测器去检测下一帧预测位置是否是目标，然后再使用新检测结果去更新训练集进而更新目标检测器。而在训练目标检测器时一般选取目标区域为正样本，目标的周围区域为负样本，当然越靠近目标的区域分为正样本的概率越高。&lt;/p&gt;
&lt;p&gt;​        本篇博文希望借这篇文章阐述KCF的原理和过程，以及存在的一些问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="correlation filter" scheme="http://yoursite.com/tags/correlation-filter/"/>
    
      <category term="kernelized correlation filter" scheme="http://yoursite.com/tags/kernelized-correlation-filter/"/>
    
      <category term="tracking" scheme="http://yoursite.com/tags/tracking/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记-Frame-wise Motion and Appearance for Real-time Multiple Object Tracking</title>
    <link href="http://yoursite.com/2019/05/17/Frame-wise-Motion-and-Appearance-for-Real-time-Multiple-Object-Tracking/"/>
    <id>http://yoursite.com/2019/05/17/Frame-wise-Motion-and-Appearance-for-Real-time-Multiple-Object-Tracking/</id>
    <published>2019-05-17T14:22:28.000Z</published>
    <updated>2019-05-21T15:08:58.162Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;文章认为MOT当前的主要挑战在于“不同帧中目标个数不定带来算法效率下降”。 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LSTM 只处理了single object。(也有处理多目标的)&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Re-ID exhausitively 匹配目标表观。（这个不客观，大多数方法都会通过先验条件约束范围）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;单个box处理耗时严重，因为需要crop+resize+extract features&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;文章针对该问题提出一种同时 关联不定数目目标的Deep Neural Network (DNN)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Frame-wise Motion Fields (FMF) 估计目标运动位置，进行初步匹配。&lt;/li&gt;
&lt;li&gt;Frame-wise Apearance Features(FAF)针对于FMF失败情形，采用表观再次匹配&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在MOT17 benchmark上保持SOTA性能同时，速度大幅提升。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="MOT" scheme="http://yoursite.com/tags/MOT/"/>
    
      <category term="Motion and Appearance" scheme="http://yoursite.com/tags/Motion-and-Appearance/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记-MOT16:A Benchmark for Multi-Object Tracking</title>
    <link href="http://yoursite.com/2019/05/17/MOT16-A-Benchmark-for-Multi-Object-Tracking/"/>
    <id>http://yoursite.com/2019/05/17/MOT16-A-Benchmark-for-Multi-Object-Tracking/</id>
    <published>2019-05-17T12:51:27.000Z</published>
    <updated>2019-05-21T15:08:29.824Z</updated>
    
    <summary type="html">
    
      &lt;h4 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h4&gt;&lt;p&gt;这篇文章主要介绍了MOT的2016 benchmark库。相对于MOT15的benchmark而言，MOT16 benchmark视频数据标注更加规范严格，除了标注pedestrian之外，还标注了其他部分类别，同时给出了每个标注的可见度。新的benchmark数据也更加多样。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MOT" scheme="http://yoursite.com/tags/MOT/"/>
    
      <category term="Benchmark" scheme="http://yoursite.com/tags/Benchmark/"/>
    
  </entry>
  
  <entry>
    <title>hello world</title>
    <link href="http://yoursite.com/2019/05/17/hello-world/"/>
    <id>http://yoursite.com/2019/05/17/hello-world/</id>
    <published>2019-05-17T10:13:10.000Z</published>
    <updated>2019-05-21T15:09:20.908Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Hello-World&quot;&gt;&lt;a href=&quot;#Hello-World&quot; class=&quot;headerlink&quot; title=&quot;Hello World&quot;&gt;&lt;/a&gt;Hello World&lt;/h3&gt;&lt;p&gt;使用Hexo + GithubPage创建个人网站总结与验证。&lt;/p&gt;
    
    </summary>
    
    
      <category term="test" scheme="http://yoursite.com/tags/test/"/>
    
  </entry>
  
</feed>
